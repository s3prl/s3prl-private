<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <meta name="generator" content="sphinx-5.1.1, furo 2022.09.15"/>
        <title>sklearn.model_selection._search - S3PRL 0.4.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?digest=9ec31e2665bf879c1d47d93a8ec4893870ee1e45" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">S3PRL 0.4.2
 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  
  <span class="sidebar-brand-text">S3PRL 0.4.2
 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial/installation.html">Install S3PRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial/upstream_collection.html">S3PRL Upstream Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial/problem.html">Use Problem module to run customizable recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How to Contribute</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute/public.html">Contribute to S3PRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute/private.html">Internal S3PRL Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.nn.html">nn</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.common.html">common</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.hear.html">hear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.interface.html">interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.linear.html">linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.pit.html">pit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.pooling.html">pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.rnn.html">rnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.speaker_loss.html">speaker_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.speaker_model.html">speaker_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.specaug.html">specaug</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.nn.upstream.html">upstream</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.problem.html">problem</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asr.html">asr</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asr.run.html">run</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asr.superb_asr.html">superb_asr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asr.superb_pr.html">superb_pr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asr.superb_sf.html">superb_sf</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asv.html">asv</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asv.run.html">run</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.asv.superb_asv.html">superb_asv</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.problem.base.html">base</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.html">common</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_beijing_opera.html">hear_beijing_opera</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_cremad.html">hear_cremad</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_dcase_2016_task2.html">hear_dcase_2016_task2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_esc50.html">hear_esc50</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_fsd.html">hear_fsd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_gsc5hr.html">hear_gsc5hr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_gtzan.html">hear_gtzan</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_gtzan_music_speech.html">hear_gtzan_music_speech</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_gunshot.html">hear_gunshot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_libricount.html">hear_libricount</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_maestro.html">hear_maestro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_nsynth5hr.html">hear_nsynth5hr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_stroke.html">hear_stroke</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_tonic.html">hear_tonic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_vocal.html">hear_vocal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.hear_vox_lingual.html">hear_vox_lingual</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.run.html">run</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.superb_er.html">superb_er</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.superb_ic.html">superb_ic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.superb_ks.html">superb_ks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.common.superb_sid.html">superb_sid</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.problem.diarization.html">diarization</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.diarization.run.html">run</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.diarization.superb_sd.html">superb_sd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.problem.diarization.util.html">util</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.task.html">task</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.base.html">base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.diarization.html">diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.dump_feature.html">dump_feature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.hear_scene.html">hear_scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.hear_timestamp.html">hear_timestamp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.speaker_verification_task.html">speaker_verification_task</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.speech2text_ctc_task.html">speech2text_ctc_task</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.task.utterance_classification_task.html">utterance_classification_task</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.html">dataio</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.html">corpus</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.base.html">base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.fluent_speech_commands.html">fluent_speech_commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.hear.html">hear</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.iemocap.html">iemocap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.librilight.html">librilight</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.librispeech.html">librispeech</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.quesst14.html">quesst14</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.snips.html">snips</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.speech_commands.html">speech_commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.voxceleb1sid.html">voxceleb1sid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.corpus.voxceleb1sv.html">voxceleb1sv</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.encoder.html">encoder</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.encoder.category.html">category</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.encoder.g2p.html">g2p</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.encoder.tokenizer.html">tokenizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.encoder.vocabulary.html">vocabulary</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.html">sampler</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.balanced_weighted_sampler.html">balanced_weighted_sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.distributed_sampler.html">distributed_sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.fixed_batch_size_batch_sampler.html">fixed_batch_size_batch_sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.group_same_item_sampler.html">group_same_item_sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.max_timestamp_batch_sampler.html">max_timestamp_batch_sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/s3prl.dataio.sampler.sorted_sampler.html">sorted_sampler</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.metric.html">metric</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.metric.common.html">common</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.metric.diarization.html">diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.metric.slot_filling.html">slot_filling</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/s3prl.util.html">util</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.util.benchmark.html">benchmark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.util.download.html">download</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.util.override.html">override</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.util.pseudo_data.html">pseudo_data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/s3prl.util.seed.html">seed</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for sklearn.model_selection._search</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The :mod:`sklearn.model_selection._search` includes utilities to fine-tune the</span>
<span class="sd">parameters of an estimator.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;,</span>
<span class="c1">#         Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="c1">#         Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="c1">#         Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1">#         Raghav RV &lt;rvraghav93@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Iterable</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span><span class="p">,</span> <span class="n">reduce</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.ma</span> <span class="kn">import</span> <span class="n">MaskedArray</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">rankdata</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">MetaEstimatorMixin</span>
<span class="kn">from</span> <span class="nn">._split</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">._validation</span> <span class="kn">import</span> <span class="n">_fit_and_score</span>
<span class="kn">from</span> <span class="nn">._validation</span> <span class="kn">import</span> <span class="n">_aggregate_score_dicts</span>
<span class="kn">from</span> <span class="nn">._validation</span> <span class="kn">import</span> <span class="n">_insert_error_scores</span>
<span class="kn">from</span> <span class="nn">._validation</span> <span class="kn">import</span> <span class="n">_normalize_score_results</span>
<span class="kn">from</span> <span class="nn">._validation</span> <span class="kn">import</span> <span class="n">_warn_or_raise_about_fit_failures</span>
<span class="kn">from</span> <span class="nn">..exceptions</span> <span class="kn">import</span> <span class="n">NotFittedError</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">..utils.random</span> <span class="kn">import</span> <span class="n">sample_without_replacement</span>
<span class="kn">from</span> <span class="nn">..utils._tags</span> <span class="kn">import</span> <span class="n">_safe_tags</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">indexable</span><span class="p">,</span> <span class="n">check_is_fitted</span><span class="p">,</span> <span class="n">_check_fit_params</span>
<span class="kn">from</span> <span class="nn">..utils.metaestimators</span> <span class="kn">import</span> <span class="n">available_if</span>
<span class="kn">from</span> <span class="nn">..utils.fixes</span> <span class="kn">import</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">..metrics._scorer</span> <span class="kn">import</span> <span class="n">_check_multimetric_scoring</span>
<span class="kn">from</span> <span class="nn">..metrics</span> <span class="kn">import</span> <span class="n">check_scoring</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;GridSearchCV&quot;</span><span class="p">,</span> <span class="s2">&quot;ParameterGrid&quot;</span><span class="p">,</span> <span class="s2">&quot;ParameterSampler&quot;</span><span class="p">,</span> <span class="s2">&quot;RandomizedSearchCV&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="ParameterGrid"><a class="viewcode-back" href="../../../_autosummary/s3prl.task.hear_timestamp.html#s3prl.task.hear_timestamp.ParameterGrid">[docs]</a><span class="k">class</span> <span class="nc">ParameterGrid</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Grid of parameters with a discrete number of values for each.</span>

<span class="sd">    Can be used to iterate over parameter value combinations with the</span>
<span class="sd">    Python built-in function iter.</span>
<span class="sd">    The order of the generated parameter combinations is deterministic.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;grid_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param_grid : dict of str to sequence, or sequence of such</span>
<span class="sd">        The parameter grid to explore, as a dictionary mapping estimator</span>
<span class="sd">        parameters to sequences of allowed values.</span>

<span class="sd">        An empty dict signifies default parameters.</span>

<span class="sd">        A sequence of dicts signifies a sequence of grids to search, and is</span>
<span class="sd">        useful to avoid exploring parameter combinations that make no sense</span>
<span class="sd">        or have no effect. See the examples below.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import ParameterGrid</span>
<span class="sd">    &gt;&gt;&gt; param_grid = {&#39;a&#39;: [1, 2], &#39;b&#39;: [True, False]}</span>
<span class="sd">    &gt;&gt;&gt; list(ParameterGrid(param_grid)) == (</span>
<span class="sd">    ...    [{&#39;a&#39;: 1, &#39;b&#39;: True}, {&#39;a&#39;: 1, &#39;b&#39;: False},</span>
<span class="sd">    ...     {&#39;a&#39;: 2, &#39;b&#39;: True}, {&#39;a&#39;: 2, &#39;b&#39;: False}])</span>
<span class="sd">    True</span>

<span class="sd">    &gt;&gt;&gt; grid = [{&#39;kernel&#39;: [&#39;linear&#39;]}, {&#39;kernel&#39;: [&#39;rbf&#39;], &#39;gamma&#39;: [1, 10]}]</span>
<span class="sd">    &gt;&gt;&gt; list(ParameterGrid(grid)) == [{&#39;kernel&#39;: &#39;linear&#39;},</span>
<span class="sd">    ...                               {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 1},</span>
<span class="sd">    ...                               {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 10}]</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; ParameterGrid(grid)[1] == {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 1}</span>
<span class="sd">    True</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    GridSearchCV : Uses :class:`ParameterGrid` to perform a full parallelized</span>
<span class="sd">        parameter search.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="p">(</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Parameter grid should be a dict or a list, got: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">!r}</span><span class="s2"> of&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="c1"># wrap dictionary in a singleton list to support either dict</span>
            <span class="c1"># or list of dicts</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span><span class="n">param_grid</span><span class="p">]</span>

        <span class="c1"># check if all entries are dictionaries of lists</span>
        <span class="k">for</span> <span class="n">grid</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter grid is not a dict (</span><span class="si">{</span><span class="n">grid</span><span class="si">!r}</span><span class="s2">)&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">grid</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Parameter array for </span><span class="si">{</span><span class="n">key</span><span class="si">!r}</span><span class="s2"> should be one-dimensional, got:&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">value</span><span class="si">!r}</span><span class="s2"> with shape </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Parameter grid for parameter </span><span class="si">{</span><span class="n">key</span><span class="si">!r}</span><span class="s2"> needs to be a list or a&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot; numpy array, but got </span><span class="si">{</span><span class="n">value</span><span class="si">!r}</span><span class="s2"> (of type &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) instead. Single values &quot;</span>
                        <span class="s2">&quot;need to be wrapped in a list with one element.&quot;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Parameter grid for parameter </span><span class="si">{</span><span class="n">key</span><span class="si">!r}</span><span class="s2"> need &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;to be a non-empty sequence, got: </span><span class="si">{</span><span class="n">value</span><span class="si">!r}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Iterate over the points in the grid.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : iterator over dict of str to any</span>
<span class="sd">            Yields dictionaries mapping each estimator parameter to one of its</span>
<span class="sd">            allowed values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">:</span>
            <span class="c1"># Always sort the keys of a dictionary, for reproducibility</span>
            <span class="n">items</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">items</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">{}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">keys</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">items</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">values</span><span class="p">):</span>
                    <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
                    <span class="k">yield</span> <span class="n">params</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of points on the grid.&quot;&quot;&quot;</span>
        <span class="c1"># Product function that can handle iterables (np.product can&#39;t).</span>
        <span class="n">product</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">reduce</span><span class="p">,</span> <span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">product</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="k">if</span> <span class="n">p</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the parameters that would be ``ind``th in iteration</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ind : int</span>
<span class="sd">            The iteration index</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict of str to any</span>
<span class="sd">            Equal to list(self)[ind]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This is used to make discrete sampling without replacement memory</span>
        <span class="c1"># efficient.</span>
        <span class="k">for</span> <span class="n">sub_grid</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">:</span>
            <span class="c1"># XXX: could memoize information used here</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">sub_grid</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">ind</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">{}</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ind</span> <span class="o">-=</span> <span class="mi">1</span>
                    <span class="k">continue</span>

            <span class="c1"># Reverse so most frequent cycling parameter comes first</span>
            <span class="n">keys</span><span class="p">,</span> <span class="n">values_lists</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">sorted</span><span class="p">(</span><span class="n">sub_grid</span><span class="o">.</span><span class="n">items</span><span class="p">())[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">v_list</span><span class="p">)</span> <span class="k">for</span> <span class="n">v_list</span> <span class="ow">in</span> <span class="n">values_lists</span><span class="p">]</span>
            <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">ind</span> <span class="o">&gt;=</span> <span class="n">total</span><span class="p">:</span>
                <span class="c1"># Try the next grid</span>
                <span class="n">ind</span> <span class="o">-=</span> <span class="n">total</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">v_list</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">values_lists</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
                    <span class="n">ind</span><span class="p">,</span> <span class="n">offset</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">v_list</span><span class="p">[</span><span class="n">offset</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">out</span>

        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s2">&quot;ParameterGrid index out of range&quot;</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">ParameterSampler</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Generator on parameters sampled from given distributions.</span>

<span class="sd">    Non-deterministic iterable over random candidate combinations for hyper-</span>
<span class="sd">    parameter search. If all parameters are presented as a list,</span>
<span class="sd">    sampling without replacement is performed. If at least one parameter</span>
<span class="sd">    is given as a distribution, sampling with replacement is used.</span>
<span class="sd">    It is highly recommended to use continuous distributions for continuous</span>
<span class="sd">    parameters.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;grid_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    param_distributions : dict</span>
<span class="sd">        Dictionary with parameters names (`str`) as keys and distributions</span>
<span class="sd">        or lists of parameters to try. Distributions must provide a ``rvs``</span>
<span class="sd">        method for sampling (such as those from scipy.stats.distributions).</span>
<span class="sd">        If a list is given, it is sampled uniformly.</span>
<span class="sd">        If a list of dicts is given, first a dict is sampled uniformly, and</span>
<span class="sd">        then a parameter is sampled using that dict as above.</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Number of parameter settings that are produced.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Pseudo random number generator state used for random uniform sampling</span>
<span class="sd">        from lists of possible values instead of scipy.stats distributions.</span>
<span class="sd">        Pass an int for reproducible output across multiple</span>
<span class="sd">        function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : dict of str to any</span>
<span class="sd">        **Yields** dictionaries mapping each estimator parameter to</span>
<span class="sd">        as sampled value.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import ParameterSampler</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats.distributions import expon</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.RandomState(0)</span>
<span class="sd">    &gt;&gt;&gt; param_grid = {&#39;a&#39;:[1, 2], &#39;b&#39;: expon()}</span>
<span class="sd">    &gt;&gt;&gt; param_list = list(ParameterSampler(param_grid, n_iter=4,</span>
<span class="sd">    ...                                    random_state=rng))</span>
<span class="sd">    &gt;&gt;&gt; rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())</span>
<span class="sd">    ...                 for d in param_list]</span>
<span class="sd">    &gt;&gt;&gt; rounded_list == [{&#39;b&#39;: 0.89856, &#39;a&#39;: 1},</span>
<span class="sd">    ...                  {&#39;b&#39;: 0.923223, &#39;a&#39;: 1},</span>
<span class="sd">    ...                  {&#39;b&#39;: 1.878964, &#39;a&#39;: 2},</span>
<span class="sd">    ...                  {&#39;b&#39;: 1.038159, &#39;a&#39;: 2}]</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_distributions</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_distributions</span><span class="p">,</span> <span class="p">(</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Parameter distribution is not a dict or a list,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; got: </span><span class="si">{</span><span class="n">param_distributions</span><span class="si">!r}</span><span class="s2"> of type &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">param_distributions</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_distributions</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="c1"># wrap dictionary in a singleton list to support either dict</span>
            <span class="c1"># or list of dicts</span>
            <span class="n">param_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="n">param_distributions</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">param_distributions</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Parameter distribution is not a dict (</span><span class="si">{!r}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">dist</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="n">dist</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="s2">&quot;rvs&quot;</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Parameter grid for parameter </span><span class="si">{</span><span class="n">key</span><span class="si">!r}</span><span class="s2"> is not iterable &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;or a distribution (value=</span><span class="si">{</span><span class="n">dist</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span>
                    <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span> <span class="o">=</span> <span class="n">param_distributions</span>

    <span class="k">def</span> <span class="nf">_is_all_lists</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">all</span><span class="p">(</span><span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="s2">&quot;rvs&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dist</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="c1"># if all distributions are given as lists, we want to sample without</span>
        <span class="c1"># replacement</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_all_lists</span><span class="p">():</span>
            <span class="c1"># look up sampled parameter settings in parameter grid</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">)</span>
            <span class="n">grid_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
            <span class="n">n_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>

            <span class="k">if</span> <span class="n">grid_size</span> <span class="o">&lt;</span> <span class="n">n_iter</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;The total space of parameters </span><span class="si">%d</span><span class="s2"> is smaller &quot;</span>
                    <span class="s2">&quot;than n_iter=</span><span class="si">%d</span><span class="s2">. Running </span><span class="si">%d</span><span class="s2"> iterations. For exhaustive &quot;</span>
                    <span class="s2">&quot;searches, use GridSearchCV.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">grid_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">),</span>
                    <span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">n_iter</span> <span class="o">=</span> <span class="n">grid_size</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample_without_replacement</span><span class="p">(</span><span class="n">grid_size</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">param_grid</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">)</span>
                <span class="c1"># Always sort the keys of a dictionary, for reproducibility</span>
                <span class="n">items</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
                <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="s2">&quot;rvs&quot;</span><span class="p">):</span>
                        <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">))]</span>
                <span class="k">yield</span> <span class="n">params</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of points that will be sampled.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_all_lists</span><span class="p">():</span>
            <span class="n">grid_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>


<span class="k">def</span> <span class="nf">_check_refit</span><span class="p">(</span><span class="n">search_cv</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">search_cv</span><span class="o">.</span><span class="n">refit</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;This </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">search_cv</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> instance was initialized with &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;`refit=False`. </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2"> is available only after refitting on the best &quot;</span>
            <span class="s2">&quot;parameters. You can refit an estimator manually using the &quot;</span>
            <span class="s2">&quot;`best_params_` attribute&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_estimator_has</span><span class="p">(</span><span class="n">attr</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Check if we can delegate a method to the underlying estimator.</span>

<span class="sd">    Calling a prediction method will only be available if `refit=True`. In</span>
<span class="sd">    such case, we check first the fitted best estimator. If it is not</span>
<span class="sd">    fitted, we check the unfitted estimator.</span>

<span class="sd">    Checking the unfitted estimator allows to use `hasattr` on the `SearchCV`</span>
<span class="sd">    instance even before calling `fit`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">_check_refit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;best_estimator_&quot;</span><span class="p">):</span>
            <span class="c1"># raise an AttributeError if `attr` does not exist</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="c1"># raise an AttributeError if `attr` does not exist</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="n">check</span>


<span class="k">class</span> <span class="nc">BaseSearchCV</span><span class="p">(</span><span class="n">MetaEstimatorMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Abstract base class for hyper parameter search with cross-validation.&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;2*n_jobs&quot;</span><span class="p">,</span>
        <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
        <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refit</span> <span class="o">=</span> <span class="n">refit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_dispatch</span> <span class="o">=</span> <span class="n">pre_dispatch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_score</span> <span class="o">=</span> <span class="n">error_score</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span> <span class="o">=</span> <span class="n">return_train_score</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_estimator_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">_estimator_type</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># allows cross-validation to see &#39;precomputed&#39; metrics</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;pairwise&quot;</span><span class="p">:</span> <span class="n">_safe_tags</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;pairwise&quot;</span><span class="p">),</span>
            <span class="s2">&quot;_xfail_checks&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;check_supervised_y_2d&quot;</span><span class="p">:</span> <span class="s2">&quot;DataConversionWarning not caught&quot;</span>
            <span class="p">},</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the score on the given data, if the estimator has been refit.</span>

<span class="sd">        This uses the score defined by ``scoring`` where provided, and the</span>
<span class="sd">        ``best_estimator_.score`` method otherwise.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Input data, where `n_samples` is the number of samples and</span>
<span class="sd">            `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples, n_output) \</span>
<span class="sd">            or (n_samples,), default=None</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The score defined by ``scoring`` if provided, and the</span>
<span class="sd">            ``best_estimator_.score`` method otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_check_refit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">)</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No score function explicitly defined, &quot;</span>
                <span class="s2">&quot;and the estimator doesn&#39;t provide one </span><span class="si">%s</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimetric_</span><span class="p">:</span>
                <span class="n">scorer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">scorer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span>
            <span class="k">return</span> <span class="n">scorer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># callable</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimetric_</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">score</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;score_samples&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">score_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call score_samples on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``score_samples``.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : iterable</span>
<span class="sd">            Data to predict on. Must fulfill input requirements</span>
<span class="sd">            of the underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_score : ndarray of shape (n_samples,)</span>
<span class="sd">            The ``best_estimator_.score_samples`` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred : ndarray of shape (n_samples,)</span>
<span class="sd">            The predicted labels or values for `X` based on the estimator with</span>
<span class="sd">            the best found parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;predict_proba&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict_proba on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict_proba``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">            Predicted class probabilities for `X` based on the estimator with</span>
<span class="sd">            the best found parameters. The order of the classes corresponds</span>
<span class="sd">            to that in the fitted attribute :term:`classes_`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;predict_log_proba&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">predict_log_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict_log_proba on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict_log_proba``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">            Predicted class log-probabilities for `X` based on the estimator</span>
<span class="sd">            with the best found parameters. The order of the classes</span>
<span class="sd">            corresponds to that in the fitted attribute :term:`classes_`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict_log_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;decision_function&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call decision_function on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``decision_function``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_score : ndarray of shape (n_samples,) or (n_samples, n_classes) \</span>
<span class="sd">                or (n_samples, n_classes * (n_classes-1) / 2)</span>
<span class="sd">            Result of the decision function for `X` based on the estimator with</span>
<span class="sd">            the best found parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call transform on the estimator with the best found parameters.</span>

<span class="sd">        Only available if the underlying estimator supports ``transform`` and</span>
<span class="sd">        ``refit=True``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            `X` transformed in the new space based on the estimator with</span>
<span class="sd">            the best found parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="nd">@available_if</span><span class="p">(</span><span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;inverse_transform&quot;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xt</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call inverse_transform on the estimator with the best found params.</span>

<span class="sd">        Only available if the underlying estimator implements</span>
<span class="sd">        ``inverse_transform`` and ``refit=True``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xt : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Result of the `inverse_transform` function for `Xt` based on the</span>
<span class="sd">            estimator with the best found parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_features_in_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of features seen during :term:`fit`.</span>

<span class="sd">        Only available when `refit=True`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># For consistency with other estimators we raise a AttributeError so</span>
        <span class="c1"># that hasattr() fails if the search estimator isn&#39;t fitted.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">NotFittedError</span> <span class="k">as</span> <span class="n">nfe</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> object has no n_features_in_ attribute.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="p">)</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">nfe</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">n_features_in_</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">classes_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Class labels.</span>

<span class="sd">        Only available when `refit=True` and the estimator is a classifier.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_estimator_has</span><span class="p">(</span><span class="s2">&quot;classes_&quot;</span><span class="p">)(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">classes_</span>

    <span class="k">def</span> <span class="nf">_run_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluate_candidates</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Repeatedly calls `evaluate_candidates` to conduct a search.</span>

<span class="sd">        This method, implemented in sub-classes, makes it possible to</span>
<span class="sd">        customize the scheduling of evaluations: GridSearchCV and</span>
<span class="sd">        RandomizedSearchCV schedule evaluations for their whole parameter</span>
<span class="sd">        search space at once but other more sequential approaches are also</span>
<span class="sd">        possible: for instance is possible to iteratively schedule evaluations</span>
<span class="sd">        for new regions of the parameter search space based on previously</span>
<span class="sd">        collected evaluation results. This makes it possible to implement</span>
<span class="sd">        Bayesian optimization or more generally sequential model-based</span>
<span class="sd">        optimization by deriving from the BaseSearchCV abstract base class.</span>
<span class="sd">        For example, Successive Halving is implemented by calling</span>
<span class="sd">        `evaluate_candidates` multiples times (once per iteration of the SH</span>
<span class="sd">        process), each time passing a different set of candidates with `X`</span>
<span class="sd">        and `y` of increasing sizes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        evaluate_candidates : callable</span>
<span class="sd">            This callback accepts:</span>
<span class="sd">                - a list of candidates, where each candidate is a dict of</span>
<span class="sd">                  parameter settings.</span>
<span class="sd">                - an optional `cv` parameter which can be used to e.g.</span>
<span class="sd">                  evaluate candidates on different dataset splits, or</span>
<span class="sd">                  evaluate candidates on subsampled data (as done in the</span>
<span class="sd">                  SucessiveHaling estimators). By default, the original `cv`</span>
<span class="sd">                  parameter is used, and it is available as a private</span>
<span class="sd">                  `_checked_cv_orig` attribute.</span>
<span class="sd">                - an optional `more_results` dict. Each key will be added to</span>
<span class="sd">                  the `cv_results_` attribute. Values should be lists of</span>
<span class="sd">                  length `n_candidates`</span>

<span class="sd">            It returns a dict of all results so far, formatted like</span>
<span class="sd">            ``cv_results_``.</span>

<span class="sd">            Important note (relevant whether the default cv is used or not):</span>
<span class="sd">            in randomized splitters, and unless the random_state parameter of</span>
<span class="sd">            cv was set to an int, calling cv.split() multiple times will</span>
<span class="sd">            yield different splits. Since cv.split() is called in</span>
<span class="sd">            evaluate_candidates, this means that candidates will be evaluated</span>
<span class="sd">            on different splits each time evaluate_candidates is called. This</span>
<span class="sd">            might be a methodological issue depending on the search strategy</span>
<span class="sd">            that you&#39;re implementing. To prevent randomized splitters from</span>
<span class="sd">            being used, you may use _split._yields_constant_splits()</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        ::</span>

<span class="sd">            def _run_search(self, evaluate_candidates):</span>
<span class="sd">                &#39;Try C=0.1 only if C=1 is better than C=10&#39;</span>
<span class="sd">                all_results = evaluate_candidates([{&#39;C&#39;: 1}, {&#39;C&#39;: 10}])</span>
<span class="sd">                score = all_results[&#39;mean_test_score&#39;]</span>
<span class="sd">                if score[0] &lt; score[1]:</span>
<span class="sd">                    evaluate_candidates([{&#39;C&#39;: 0.1}])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;_run_search not implemented.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_refit_for_multimetric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check `refit` is compatible with `scores` is valid&quot;&quot;&quot;</span>
        <span class="n">multimetric_refit_msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;For multi-metric scoring, the parameter refit must be set to a &quot;</span>
            <span class="s2">&quot;scorer key or a callable to refit an estimator with the best &quot;</span>
            <span class="s2">&quot;parameter setting on the whole data and make the best_* &quot;</span>
            <span class="s2">&quot;attributes available for that metric. If this is not needed, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;refit should be set to False explicitly. </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="si">!r}</span><span class="s2"> was &quot;</span>
            <span class="s2">&quot;passed.&quot;</span>
        <span class="p">)</span>

        <span class="n">valid_refit_dict</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">refit</span> <span class="ow">in</span> <span class="n">scores</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">refit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">valid_refit_dict</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">multimetric_refit_msg</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_select_best_index</span><span class="p">(</span><span class="n">refit</span><span class="p">,</span> <span class="n">refit_metric</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Select index of the best combination of hyperparemeters.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">refit</span><span class="p">):</span>
            <span class="c1"># If callable, refit is expected to return the index of the best</span>
            <span class="c1"># parameter set.</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="n">refit</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">best_index</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;best_index_ returned is not an integer&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">best_index</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">best_index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s2">&quot;best_index_ index out of range&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;rank_test_</span><span class="si">{</span><span class="n">refit_metric</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">best_index</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run fit with all sets of parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where `n_samples` is the number of samples and</span>
<span class="sd">            `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples, n_output) \</span>
<span class="sd">            or (n_samples,), default=None</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set. Only used in conjunction with a &quot;Group&quot; :term:`cv`</span>
<span class="sd">            instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).</span>

<span class="sd">        **fit_params : dict of str -&gt; object</span>
<span class="sd">            Parameters passed to the `fit` method of the estimator.</span>

<span class="sd">            If a fit parameter is an array-like whose length is equal to</span>
<span class="sd">            `num_samples` then it will be split across CV groups along with `X`</span>
<span class="sd">            and `y`. For example, the :term:`sample_weight` parameter is split</span>
<span class="sd">            because `len(sample_weights) = len(X)`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Instance of fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span>
        <span class="n">refit_metric</span> <span class="o">=</span> <span class="s2">&quot;score&quot;</span>

        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">):</span>
            <span class="n">scorers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">scorers</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scorers</span> <span class="o">=</span> <span class="n">_check_multimetric_scoring</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_refit_for_multimetric</span><span class="p">(</span><span class="n">scorers</span><span class="p">)</span>
            <span class="n">refit_metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refit</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">fit_params</span> <span class="o">=</span> <span class="n">_check_fit_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">)</span>

        <span class="n">cv_orig</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="n">cv_orig</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>

        <span class="n">base_estimator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">)</span>

        <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_dispatch</span><span class="p">)</span>

        <span class="n">fit_and_score_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">scorer</span><span class="o">=</span><span class="n">scorers</span><span class="p">,</span>
            <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">,</span>
            <span class="n">return_n_test_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_times</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_parameters</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">error_score</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">error_score</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">all_candidate_params</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">all_out</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">all_more_results</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">evaluate_candidates</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">more_results</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
                <span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span> <span class="ow">or</span> <span class="n">cv_orig</span>
                <span class="n">candidate_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">)</span>
                <span class="n">n_candidates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;Fitting </span><span class="si">{0}</span><span class="s2"> folds for each of </span><span class="si">{1}</span><span class="s2"> candidates,&quot;</span>
                        <span class="s2">&quot; totalling </span><span class="si">{2}</span><span class="s2"> fits&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">n_splits</span><span class="p">,</span> <span class="n">n_candidates</span><span class="p">,</span> <span class="n">n_candidates</span> <span class="o">*</span> <span class="n">n_splits</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                <span class="n">out</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
                    <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span>
                        <span class="n">clone</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">),</span>
                        <span class="n">X</span><span class="p">,</span>
                        <span class="n">y</span><span class="p">,</span>
                        <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                        <span class="n">test</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>
                        <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
                        <span class="n">split_progress</span><span class="o">=</span><span class="p">(</span><span class="n">split_idx</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">),</span>
                        <span class="n">candidate_progress</span><span class="o">=</span><span class="p">(</span><span class="n">cand_idx</span><span class="p">,</span> <span class="n">n_candidates</span><span class="p">),</span>
                        <span class="o">**</span><span class="n">fit_and_score_kwargs</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">cand_idx</span><span class="p">,</span> <span class="n">parameters</span><span class="p">),</span> <span class="p">(</span><span class="n">split_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span>
                        <span class="nb">enumerate</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">),</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">))</span>
                    <span class="p">)</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;No fits were performed. &quot;</span>
                        <span class="s2">&quot;Was the CV iterator empty? &quot;</span>
                        <span class="s2">&quot;Were there no candidates?&quot;</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n_candidates</span> <span class="o">*</span> <span class="n">n_splits</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;cv.split and cv.get_n_splits returned &quot;</span>
                        <span class="s2">&quot;inconsistent results. Expected </span><span class="si">{}</span><span class="s2"> &quot;</span>
                        <span class="s2">&quot;splits, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">//</span> <span class="n">n_candidates</span><span class="p">)</span>
                    <span class="p">)</span>

                <span class="n">_warn_or_raise_about_fit_failures</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_score</span><span class="p">)</span>

                <span class="c1"># For callable self.scoring, the return type is only know after</span>
                <span class="c1"># calling. If the return type is a dictionary, the error scores</span>
                <span class="c1"># can now be inserted with the correct key. The type checking</span>
                <span class="c1"># of out will be done in `_insert_error_scores`.</span>
                <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">):</span>
                    <span class="n">_insert_error_scores</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_score</span><span class="p">)</span>

                <span class="n">all_candidate_params</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">)</span>
                <span class="n">all_out</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">more_results</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">more_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">all_more_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

                <span class="k">nonlocal</span> <span class="n">results</span>
                <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_results</span><span class="p">(</span>
                    <span class="n">all_candidate_params</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">all_out</span><span class="p">,</span> <span class="n">all_more_results</span>
                <span class="p">)</span>

                <span class="k">return</span> <span class="n">results</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_run_search</span><span class="p">(</span><span class="n">evaluate_candidates</span><span class="p">)</span>

            <span class="c1"># multimetric is determined here because in the case of a callable</span>
            <span class="c1"># self.scoring the return type is only known after calling</span>
            <span class="n">first_test_score</span> <span class="o">=</span> <span class="n">all_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multimetric_</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first_test_score</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>

            <span class="c1"># check refit_metric now for a callabe scorer that is multimetric</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimetric_</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_check_refit_for_multimetric</span><span class="p">(</span><span class="n">first_test_score</span><span class="p">)</span>
                <span class="n">refit_metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refit</span>

        <span class="c1"># For multi-metric evaluation, store the best_index_, best_params_ and</span>
        <span class="c1"># best_score_ iff refit is one of the scorer names</span>
        <span class="c1"># In single metric evaluation, refit_metric is &quot;score&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">refit</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimetric_</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_index_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_best_index</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">,</span> <span class="n">refit_metric</span><span class="p">,</span> <span class="n">results</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">):</span>
                <span class="c1"># With a non-custom callable, we can select the best score</span>
                <span class="c1"># based on the best index</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;mean_test_</span><span class="si">{</span><span class="n">refit_metric</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">][</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">best_index_</span>
                <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">best_index_</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">:</span>
            <span class="c1"># we clone again after setting params in case some</span>
            <span class="c1"># of the params are estimators as well.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span>
                <span class="n">clone</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">)</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">refit_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
            <span class="n">refit_end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">refit_time_</span> <span class="o">=</span> <span class="n">refit_end_time</span> <span class="o">-</span> <span class="n">refit_start_time</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s2">&quot;feature_names_in_&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_in_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">feature_names_in_</span>

        <span class="c1"># Store the only scorer not as a dict for single metric evaluation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span> <span class="o">=</span> <span class="n">scorers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cv_results_</span> <span class="o">=</span> <span class="n">results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits_</span> <span class="o">=</span> <span class="n">n_splits</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_format_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">candidate_params</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">more_results</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_candidates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_aggregate_score_dicts</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">more_results</span> <span class="ow">or</span> <span class="p">{})</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># each value is a list (as per evaluate_candidate&#39;s convention)</span>
            <span class="c1"># we convert it to an array for consistency with the other keys</span>
            <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_store</span><span class="p">(</span><span class="n">key_name</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;A small helper to store the scores/times to the cv_results_&quot;&quot;&quot;</span>
            <span class="c1"># When iterated first by splits, then by parameters</span>
            <span class="c1"># We want `array` to have `n_candidates` rows and `n_splits` cols.</span>
            <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_candidates</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">splits</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">split_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
                    <span class="c1"># Uses closure to alter the results</span>
                    <span class="n">results</span><span class="p">[</span><span class="s2">&quot;split</span><span class="si">%d</span><span class="s2">_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">split_idx</span><span class="p">,</span> <span class="n">key_name</span><span class="p">)]</span> <span class="o">=</span> <span class="n">array</span><span class="p">[:,</span> <span class="n">split_idx</span><span class="p">]</span>

            <span class="n">array_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="s2">&quot;mean_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">array_means</span>

            <span class="k">if</span> <span class="n">key_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;train_&quot;</span><span class="p">,</span> <span class="s2">&quot;test_&quot;</span><span class="p">))</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span>
                <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">array_means</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;One or more of the </span><span class="si">{</span><span class="n">key_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> scores &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;are non-finite: </span><span class="si">{</span><span class="n">array_means</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># Weighted std is not directly available in numpy</span>
            <span class="n">array_stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">array</span> <span class="o">-</span> <span class="n">array_means</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="s2">&quot;std_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">array_stds</span>

            <span class="k">if</span> <span class="n">rank</span><span class="p">:</span>
                <span class="n">results</span><span class="p">[</span><span class="s2">&quot;rank_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                    <span class="n">rankdata</span><span class="p">(</span><span class="o">-</span><span class="n">array_means</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span>
                <span class="p">)</span>

        <span class="n">_store</span><span class="p">(</span><span class="s2">&quot;fit_time&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">])</span>
        <span class="n">_store</span><span class="p">(</span><span class="s2">&quot;score_time&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="s2">&quot;score_time&quot;</span><span class="p">])</span>
        <span class="c1"># Use one MaskedArray and mask all the places where the param is not</span>
        <span class="c1"># applicable for that candidate. Use defaultdict as each candidate may</span>
        <span class="c1"># not contain all the params</span>
        <span class="n">param_results</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span>
                <span class="n">MaskedArray</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                    <span class="n">n_candidates</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">cand_idx</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># An all masked empty array gets created for the key</span>
                <span class="c1"># `&quot;param_%s&quot; % name` at the first occurrence of `name`.</span>
                <span class="c1"># Setting the value at an index also unmasks that index</span>
                <span class="n">param_results</span><span class="p">[</span><span class="s2">&quot;param_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">][</span><span class="n">cand_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="n">results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">param_results</span><span class="p">)</span>
        <span class="c1"># Store a list of param dicts at the key &#39;params&#39;</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">candidate_params</span>

        <span class="n">test_scores_dict</span> <span class="o">=</span> <span class="n">_normalize_score_results</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;test_scores&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">train_scores_dict</span> <span class="o">=</span> <span class="n">_normalize_score_results</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;train_scores&quot;</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">scorer_name</span> <span class="ow">in</span> <span class="n">test_scores_dict</span><span class="p">:</span>
            <span class="c1"># Computed the (weighted) mean and std for test scores alone</span>
            <span class="n">_store</span><span class="p">(</span>
                <span class="s2">&quot;test_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scorer_name</span><span class="p">,</span>
                <span class="n">test_scores_dict</span><span class="p">[</span><span class="n">scorer_name</span><span class="p">],</span>
                <span class="n">splits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">rank</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">:</span>
                <span class="n">_store</span><span class="p">(</span>
                    <span class="s2">&quot;train_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scorer_name</span><span class="p">,</span>
                    <span class="n">train_scores_dict</span><span class="p">[</span><span class="n">scorer_name</span><span class="p">],</span>
                    <span class="n">splits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>


<span class="k">class</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">BaseSearchCV</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Exhaustive search over specified parameter values for an estimator.</span>

<span class="sd">    Important members are fit, predict.</span>

<span class="sd">    GridSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.</span>
<span class="sd">    It also implements &quot;score_samples&quot;, &quot;predict&quot;, &quot;predict_proba&quot;,</span>
<span class="sd">    &quot;decision_function&quot;, &quot;transform&quot; and &quot;inverse_transform&quot; if they are</span>
<span class="sd">    implemented in the estimator used.</span>

<span class="sd">    The parameters of the estimator used to apply these methods are optimized</span>
<span class="sd">    by cross-validated grid-search over a parameter grid.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;grid_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object</span>
<span class="sd">        This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">        Either estimator needs to provide a ``score`` function,</span>
<span class="sd">        or ``scoring`` must be passed.</span>

<span class="sd">    param_grid : dict or list of dictionaries</span>
<span class="sd">        Dictionary with parameters names (`str`) as keys and lists of</span>
<span class="sd">        parameter settings to try as values, or a list of such</span>
<span class="sd">        dictionaries, in which case the grids spanned by each dictionary</span>
<span class="sd">        in the list are explored. This enables searching over any sequence</span>
<span class="sd">        of parameter settings.</span>

<span class="sd">    scoring : str, callable, list, tuple or dict, default=None</span>
<span class="sd">        Strategy to evaluate the performance of the cross-validated model on</span>
<span class="sd">        the test set.</span>

<span class="sd">        If `scoring` represents a single score, one can use:</span>

<span class="sd">        - a single string (see :ref:`scoring_parameter`);</span>
<span class="sd">        - a callable (see :ref:`scoring`) that returns a single value.</span>

<span class="sd">        If `scoring` represents multiple scores, one can use:</span>

<span class="sd">        - a list or tuple of unique strings;</span>
<span class="sd">        - a callable returning a dictionary where the keys are the metric</span>
<span class="sd">          names and the values are the metric scores;</span>
<span class="sd">        - a dictionary with metric names as keys and callables a values.</span>

<span class="sd">        See :ref:`multimetric_grid_search` for an example.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">        .. versionchanged:: v0.20</span>
<span class="sd">           `n_jobs` default changed from 1 to None</span>

<span class="sd">    refit : bool, str, or callable, default=True</span>
<span class="sd">        Refit an estimator using the best found parameters on the whole</span>
<span class="sd">        dataset.</span>

<span class="sd">        For multiple metric evaluation, this needs to be a `str` denoting the</span>
<span class="sd">        scorer that would be used to find the best parameters for refitting</span>
<span class="sd">        the estimator at the end.</span>

<span class="sd">        Where there are considerations other than maximum score in</span>
<span class="sd">        choosing a best estimator, ``refit`` can be set to a function which</span>
<span class="sd">        returns the selected ``best_index_`` given ``cv_results_``. In that</span>
<span class="sd">        case, the ``best_estimator_`` and ``best_params_`` will be set</span>
<span class="sd">        according to the returned ``best_index_`` while the ``best_score_``</span>
<span class="sd">        attribute will not be available.</span>

<span class="sd">        The refitted estimator is made available at the ``best_estimator_``</span>
<span class="sd">        attribute and permits using ``predict`` directly on this</span>
<span class="sd">        ``GridSearchCV`` instance.</span>

<span class="sd">        Also for multiple metric evaluation, the attributes ``best_index_``,</span>
<span class="sd">        ``best_score_`` and ``best_params_`` will only be available if</span>
<span class="sd">        ``refit`` is set and all of them will be determined w.r.t this specific</span>
<span class="sd">        scorer.</span>

<span class="sd">        See ``scoring`` parameter to know more about multiple metric</span>
<span class="sd">        evaluation.</span>

<span class="sd">        See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`</span>
<span class="sd">        to see how to design a custom selection strategy using a callable</span>
<span class="sd">        via `refit`.</span>

<span class="sd">        .. versionchanged:: 0.20</span>
<span class="sd">            Support for callable added.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - integer, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value if None changed from 3-fold to 5-fold.</span>

<span class="sd">    verbose : int</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">        - &gt;1 : the computation time for each fold and parameter candidate is</span>
<span class="sd">          displayed;</span>
<span class="sd">        - &gt;2 : the score is also displayed;</span>
<span class="sd">        - &gt;3 : the fold and candidate parameter indexes are also displayed</span>
<span class="sd">          together with the starting time of the computation.</span>

<span class="sd">    pre_dispatch : int, or str, default=&#39;2*n_jobs&#39;</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A str, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    return_train_score : bool, default=False</span>
<span class="sd">        If ``False``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">        scores.</span>
<span class="sd">        Computing training scores is used to get insights on how different</span>
<span class="sd">        parameter settings impact the overfitting/underfitting trade-off.</span>
<span class="sd">        However computing the scores on the training set can be computationally</span>
<span class="sd">        expensive and is not strictly required to select the parameters that</span>
<span class="sd">        yield the best generalization performance.</span>

<span class="sd">        .. versionadded:: 0.19</span>

<span class="sd">        .. versionchanged:: 0.21</span>
<span class="sd">            Default value was changed from ``True`` to ``False``</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">        A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">        imported into a pandas ``DataFrame``.</span>

<span class="sd">        For instance the below given table</span>

<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|</span>
<span class="sd">        +============+===========+============+=================+===+=========+</span>
<span class="sd">        |  &#39;poly&#39;    |     --    |      2     |       0.80      |...|    2    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;poly&#39;    |     --    |      3     |       0.70      |...|    4    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;rbf&#39;     |     0.1   |     --     |       0.80      |...|    3    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;rbf&#39;     |     0.2   |     --     |       0.93      |...|    1    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>

<span class="sd">        will be represented by a ``cv_results_`` dict of::</span>

<span class="sd">            {</span>
<span class="sd">            &#39;param_kernel&#39;: masked_array(data = [&#39;poly&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                         mask = [False False False False]...)</span>
<span class="sd">            &#39;param_gamma&#39;: masked_array(data = [-- -- 0.1 0.2],</span>
<span class="sd">                                        mask = [ True  True False False]...),</span>
<span class="sd">            &#39;param_degree&#39;: masked_array(data = [2.0 3.0 -- --],</span>
<span class="sd">                                         mask = [False False  True  True]...),</span>
<span class="sd">            &#39;split0_test_score&#39;  : [0.80, 0.70, 0.80, 0.93],</span>
<span class="sd">            &#39;split1_test_score&#39;  : [0.82, 0.50, 0.70, 0.78],</span>
<span class="sd">            &#39;mean_test_score&#39;    : [0.81, 0.60, 0.75, 0.85],</span>
<span class="sd">            &#39;std_test_score&#39;     : [0.01, 0.10, 0.05, 0.08],</span>
<span class="sd">            &#39;rank_test_score&#39;    : [2, 4, 3, 1],</span>
<span class="sd">            &#39;split0_train_score&#39; : [0.80, 0.92, 0.70, 0.93],</span>
<span class="sd">            &#39;split1_train_score&#39; : [0.82, 0.55, 0.70, 0.87],</span>
<span class="sd">            &#39;mean_train_score&#39;   : [0.81, 0.74, 0.70, 0.90],</span>
<span class="sd">            &#39;std_train_score&#39;    : [0.01, 0.19, 0.00, 0.03],</span>
<span class="sd">            &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">            &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">            &#39;mean_score_time&#39;    : [0.01, 0.06, 0.04, 0.04],</span>
<span class="sd">            &#39;std_score_time&#39;     : [0.00, 0.00, 0.00, 0.01],</span>
<span class="sd">            &#39;params&#39;             : [{&#39;kernel&#39;: &#39;poly&#39;, &#39;degree&#39;: 2}, ...],</span>
<span class="sd">            }</span>

<span class="sd">        NOTE</span>

<span class="sd">        The key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">        settings dicts for all the parameter candidates.</span>

<span class="sd">        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and</span>
<span class="sd">        ``std_score_time`` are all in seconds.</span>

<span class="sd">        For multi-metric evaluation, the scores for all the scorers are</span>
<span class="sd">        available in the ``cv_results_`` dict at the keys ending with that</span>
<span class="sd">        scorer&#39;s name (``&#39;_&lt;scorer_name&gt;&#39;``) instead of ``&#39;_score&#39;`` shown</span>
<span class="sd">        above. (&#39;split0_test_precision&#39;, &#39;mean_train_precision&#39; etc.)</span>

<span class="sd">    best_estimator_ : estimator</span>
<span class="sd">        Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">        which gave highest score (or smallest loss if specified)</span>
<span class="sd">        on the left out data. Not available if ``refit=False``.</span>

<span class="sd">        See ``refit`` parameter for more information on allowed values.</span>

<span class="sd">    best_score_ : float</span>
<span class="sd">        Mean cross-validated score of the best_estimator</span>

<span class="sd">        For multi-metric evaluation, this is present only if ``refit`` is</span>
<span class="sd">        specified.</span>

<span class="sd">        This attribute is not available if ``refit`` is a function.</span>

<span class="sd">    best_params_ : dict</span>
<span class="sd">        Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">        For multi-metric evaluation, this is present only if ``refit`` is</span>
<span class="sd">        specified.</span>

<span class="sd">    best_index_ : int</span>
<span class="sd">        The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">        candidate parameter setting.</span>

<span class="sd">        The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">        the parameter setting for the best model, that gives the highest</span>
<span class="sd">        mean score (``search.best_score_``).</span>

<span class="sd">        For multi-metric evaluation, this is present only if ``refit`` is</span>
<span class="sd">        specified.</span>

<span class="sd">    scorer_ : function or a dict</span>
<span class="sd">        Scorer function used on the held out data to choose the best</span>
<span class="sd">        parameters for the model.</span>

<span class="sd">        For multi-metric evaluation, this attribute holds the validated</span>
<span class="sd">        ``scoring`` dict which maps the scorer key to the scorer callable.</span>

<span class="sd">    n_splits_ : int</span>
<span class="sd">        The number of cross-validation splits (folds/iterations).</span>

<span class="sd">    refit_time_ : float</span>
<span class="sd">        Seconds used for refitting the best model on the whole dataset.</span>

<span class="sd">        This is present only if ``refit`` is not False.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    multimetric_ : bool</span>
<span class="sd">        Whether or not the scorers compute several metrics.</span>

<span class="sd">    classes_ : ndarray of shape (n_classes,)</span>
<span class="sd">        The classes labels. This is present only if ``refit`` is specified and</span>
<span class="sd">        the underlying estimator is a classifier.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features seen during :term:`fit`. Only defined if</span>
<span class="sd">        `best_estimator_` is defined (see the documentation for the `refit`</span>
<span class="sd">        parameter for more details) and that `best_estimator_` exposes</span>
<span class="sd">        `n_features_in_` when fit.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
<span class="sd">        Names of features seen during :term:`fit`. Only defined if</span>
<span class="sd">        `best_estimator_` is defined (see the documentation for the `refit`</span>
<span class="sd">        parameter for more details) and that `best_estimator_` exposes</span>
<span class="sd">        `feature_names_in_` when fit.</span>

<span class="sd">        .. versionadded:: 1.0</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ParameterGrid : Generates all the combinations of a hyperparameter grid.</span>
<span class="sd">    train_test_split : Utility function to split the data into a development</span>
<span class="sd">        set usable for fitting a GridSearchCV instance and an evaluation set</span>
<span class="sd">        for its final evaluation.</span>
<span class="sd">    sklearn.metrics.make_scorer : Make a scorer from a performance metric or</span>
<span class="sd">        loss function.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The parameters selected are those that maximize the score of the left out</span>
<span class="sd">    data, unless an explicit score is passed in which case it is used instead.</span>

<span class="sd">    If `n_jobs` was set to a value higher than one, the data is copied for each</span>
<span class="sd">    point in the grid (and not `n_jobs` times). This is done for efficiency</span>
<span class="sd">    reasons if individual jobs take very little time, but may raise errors if</span>
<span class="sd">    the dataset is large and not enough memory is available.  A workaround in</span>
<span class="sd">    this case is to set `pre_dispatch`. Then, the memory is copied only</span>
<span class="sd">    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *</span>
<span class="sd">    n_jobs`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import svm, datasets</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GridSearchCV</span>
<span class="sd">    &gt;&gt;&gt; iris = datasets.load_iris()</span>
<span class="sd">    &gt;&gt;&gt; parameters = {&#39;kernel&#39;:(&#39;linear&#39;, &#39;rbf&#39;), &#39;C&#39;:[1, 10]}</span>
<span class="sd">    &gt;&gt;&gt; svc = svm.SVC()</span>
<span class="sd">    &gt;&gt;&gt; clf = GridSearchCV(svc, parameters)</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(iris.data, iris.target)</span>
<span class="sd">    GridSearchCV(estimator=SVC(),</span>
<span class="sd">                 param_grid={&#39;C&#39;: [1, 10], &#39;kernel&#39;: (&#39;linear&#39;, &#39;rbf&#39;)})</span>
<span class="sd">    &gt;&gt;&gt; sorted(clf.cv_results_.keys())</span>
<span class="sd">    [&#39;mean_fit_time&#39;, &#39;mean_score_time&#39;, &#39;mean_test_score&#39;,...</span>
<span class="sd">     &#39;param_C&#39;, &#39;param_kernel&#39;, &#39;params&#39;,...</span>
<span class="sd">     &#39;rank_test_score&#39;, &#39;split0_test_score&#39;,...</span>
<span class="sd">     &#39;split2_test_score&#39;, ...</span>
<span class="sd">     &#39;std_fit_time&#39;, &#39;std_score_time&#39;, &#39;std_test_score&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_required_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">,</span> <span class="s2">&quot;param_grid&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;2*n_jobs&quot;</span><span class="p">,</span>
        <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
        <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">refit</span><span class="o">=</span><span class="n">refit</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span>
            <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>

    <span class="k">def</span> <span class="nf">_run_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluate_candidates</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Search all candidates in param_grid&quot;&quot;&quot;</span>
        <span class="n">evaluate_candidates</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">BaseSearchCV</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Randomized search on hyper parameters.</span>

<span class="sd">    RandomizedSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.</span>
<span class="sd">    It also implements &quot;score_samples&quot;, &quot;predict&quot;, &quot;predict_proba&quot;,</span>
<span class="sd">    &quot;decision_function&quot;, &quot;transform&quot; and &quot;inverse_transform&quot; if they are</span>
<span class="sd">    implemented in the estimator used.</span>

<span class="sd">    The parameters of the estimator used to apply these methods are optimized</span>
<span class="sd">    by cross-validated search over parameter settings.</span>

<span class="sd">    In contrast to GridSearchCV, not all parameter values are tried out, but</span>
<span class="sd">    rather a fixed number of parameter settings is sampled from the specified</span>
<span class="sd">    distributions. The number of parameter settings that are tried is</span>
<span class="sd">    given by n_iter.</span>

<span class="sd">    If all parameters are presented as a list,</span>
<span class="sd">    sampling without replacement is performed. If at least one parameter</span>
<span class="sd">    is given as a distribution, sampling with replacement is used.</span>
<span class="sd">    It is highly recommended to use continuous distributions for continuous</span>
<span class="sd">    parameters.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;randomized_parameter_search&gt;`.</span>

<span class="sd">    .. versionadded:: 0.14</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object</span>
<span class="sd">        A object of that type is instantiated for each grid point.</span>
<span class="sd">        This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">        Either estimator needs to provide a ``score`` function,</span>
<span class="sd">        or ``scoring`` must be passed.</span>

<span class="sd">    param_distributions : dict or list of dicts</span>
<span class="sd">        Dictionary with parameters names (`str`) as keys and distributions</span>
<span class="sd">        or lists of parameters to try. Distributions must provide a ``rvs``</span>
<span class="sd">        method for sampling (such as those from scipy.stats.distributions).</span>
<span class="sd">        If a list is given, it is sampled uniformly.</span>
<span class="sd">        If a list of dicts is given, first a dict is sampled uniformly, and</span>
<span class="sd">        then a parameter is sampled using that dict as above.</span>

<span class="sd">    n_iter : int, default=10</span>
<span class="sd">        Number of parameter settings that are sampled. n_iter trades</span>
<span class="sd">        off runtime vs quality of the solution.</span>

<span class="sd">    scoring : str, callable, list, tuple or dict, default=None</span>
<span class="sd">        Strategy to evaluate the performance of the cross-validated model on</span>
<span class="sd">        the test set.</span>

<span class="sd">        If `scoring` represents a single score, one can use:</span>

<span class="sd">        - a single string (see :ref:`scoring_parameter`);</span>
<span class="sd">        - a callable (see :ref:`scoring`) that returns a single value.</span>

<span class="sd">        If `scoring` represents multiple scores, one can use:</span>

<span class="sd">        - a list or tuple of unique strings;</span>
<span class="sd">        - a callable returning a dictionary where the keys are the metric</span>
<span class="sd">          names and the values are the metric scores;</span>
<span class="sd">        - a dictionary with metric names as keys and callables a values.</span>

<span class="sd">        See :ref:`multimetric_grid_search` for an example.</span>

<span class="sd">        If None, the estimator&#39;s score method is used.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">        .. versionchanged:: v0.20</span>
<span class="sd">           `n_jobs` default changed from 1 to None</span>

<span class="sd">    refit : bool, str, or callable, default=True</span>
<span class="sd">        Refit an estimator using the best found parameters on the whole</span>
<span class="sd">        dataset.</span>

<span class="sd">        For multiple metric evaluation, this needs to be a `str` denoting the</span>
<span class="sd">        scorer that would be used to find the best parameters for refitting</span>
<span class="sd">        the estimator at the end.</span>

<span class="sd">        Where there are considerations other than maximum score in</span>
<span class="sd">        choosing a best estimator, ``refit`` can be set to a function which</span>
<span class="sd">        returns the selected ``best_index_`` given the ``cv_results``. In that</span>
<span class="sd">        case, the ``best_estimator_`` and ``best_params_`` will be set</span>
<span class="sd">        according to the returned ``best_index_`` while the ``best_score_``</span>
<span class="sd">        attribute will not be available.</span>

<span class="sd">        The refitted estimator is made available at the ``best_estimator_``</span>
<span class="sd">        attribute and permits using ``predict`` directly on this</span>
<span class="sd">        ``RandomizedSearchCV`` instance.</span>

<span class="sd">        Also for multiple metric evaluation, the attributes ``best_index_``,</span>
<span class="sd">        ``best_score_`` and ``best_params_`` will only be available if</span>
<span class="sd">        ``refit`` is set and all of them will be determined w.r.t this specific</span>
<span class="sd">        scorer.</span>

<span class="sd">        See ``scoring`` parameter to know more about multiple metric</span>
<span class="sd">        evaluation.</span>

<span class="sd">        .. versionchanged:: 0.20</span>
<span class="sd">            Support for callable added.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - integer, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value if None changed from 3-fold to 5-fold.</span>

<span class="sd">    verbose : int</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    pre_dispatch : int, or str, default=&#39;2*n_jobs&#39;</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A str, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Pseudo random number generator state used for random uniform sampling</span>
<span class="sd">        from lists of possible values instead of scipy.stats distributions.</span>
<span class="sd">        Pass an int for reproducible output across multiple</span>
<span class="sd">        function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    return_train_score : bool, default=False</span>
<span class="sd">        If ``False``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">        scores.</span>
<span class="sd">        Computing training scores is used to get insights on how different</span>
<span class="sd">        parameter settings impact the overfitting/underfitting trade-off.</span>
<span class="sd">        However computing the scores on the training set can be computationally</span>
<span class="sd">        expensive and is not strictly required to select the parameters that</span>
<span class="sd">        yield the best generalization performance.</span>

<span class="sd">        .. versionadded:: 0.19</span>

<span class="sd">        .. versionchanged:: 0.21</span>
<span class="sd">            Default value was changed from ``True`` to ``False``</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">        A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">        imported into a pandas ``DataFrame``.</span>

<span class="sd">        For instance the below given table</span>

<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        | param_kernel | param_gamma | split0_test_score |...|rank_test_score|</span>
<span class="sd">        +==============+=============+===================+===+===============+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.1     |       0.80        |...|       1       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.2     |       0.84        |...|       3       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.3     |       0.70        |...|       2       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>

<span class="sd">        will be represented by a ``cv_results_`` dict of::</span>

<span class="sd">            {</span>
<span class="sd">            &#39;param_kernel&#39; : masked_array(data = [&#39;rbf&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                          mask = False),</span>
<span class="sd">            &#39;param_gamma&#39;  : masked_array(data = [0.1 0.2 0.3], mask = False),</span>
<span class="sd">            &#39;split0_test_score&#39;  : [0.80, 0.84, 0.70],</span>
<span class="sd">            &#39;split1_test_score&#39;  : [0.82, 0.50, 0.70],</span>
<span class="sd">            &#39;mean_test_score&#39;    : [0.81, 0.67, 0.70],</span>
<span class="sd">            &#39;std_test_score&#39;     : [0.01, 0.24, 0.00],</span>
<span class="sd">            &#39;rank_test_score&#39;    : [1, 3, 2],</span>
<span class="sd">            &#39;split0_train_score&#39; : [0.80, 0.92, 0.70],</span>
<span class="sd">            &#39;split1_train_score&#39; : [0.82, 0.55, 0.70],</span>
<span class="sd">            &#39;mean_train_score&#39;   : [0.81, 0.74, 0.70],</span>
<span class="sd">            &#39;std_train_score&#39;    : [0.01, 0.19, 0.00],</span>
<span class="sd">            &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43],</span>
<span class="sd">            &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01],</span>
<span class="sd">            &#39;mean_score_time&#39;    : [0.01, 0.06, 0.04],</span>
<span class="sd">            &#39;std_score_time&#39;     : [0.00, 0.00, 0.00],</span>
<span class="sd">            &#39;params&#39;             : [{&#39;kernel&#39; : &#39;rbf&#39;, &#39;gamma&#39; : 0.1}, ...],</span>
<span class="sd">            }</span>

<span class="sd">        NOTE</span>

<span class="sd">        The key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">        settings dicts for all the parameter candidates.</span>

<span class="sd">        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and</span>
<span class="sd">        ``std_score_time`` are all in seconds.</span>

<span class="sd">        For multi-metric evaluation, the scores for all the scorers are</span>
<span class="sd">        available in the ``cv_results_`` dict at the keys ending with that</span>
<span class="sd">        scorer&#39;s name (``&#39;_&lt;scorer_name&gt;&#39;``) instead of ``&#39;_score&#39;`` shown</span>
<span class="sd">        above. (&#39;split0_test_precision&#39;, &#39;mean_train_precision&#39; etc.)</span>

<span class="sd">    best_estimator_ : estimator</span>
<span class="sd">        Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">        which gave highest score (or smallest loss if specified)</span>
<span class="sd">        on the left out data. Not available if ``refit=False``.</span>

<span class="sd">        For multi-metric evaluation, this attribute is present only if</span>
<span class="sd">        ``refit`` is specified.</span>

<span class="sd">        See ``refit`` parameter for more information on allowed values.</span>

<span class="sd">    best_score_ : float</span>
<span class="sd">        Mean cross-validated score of the best_estimator.</span>

<span class="sd">        For multi-metric evaluation, this is not available if ``refit`` is</span>
<span class="sd">        ``False``. See ``refit`` parameter for more information.</span>

<span class="sd">        This attribute is not available if ``refit`` is a function.</span>

<span class="sd">    best_params_ : dict</span>
<span class="sd">        Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">        For multi-metric evaluation, this is not available if ``refit`` is</span>
<span class="sd">        ``False``. See ``refit`` parameter for more information.</span>

<span class="sd">    best_index_ : int</span>
<span class="sd">        The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">        candidate parameter setting.</span>

<span class="sd">        The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">        the parameter setting for the best model, that gives the highest</span>
<span class="sd">        mean score (``search.best_score_``).</span>

<span class="sd">        For multi-metric evaluation, this is not available if ``refit`` is</span>
<span class="sd">        ``False``. See ``refit`` parameter for more information.</span>

<span class="sd">    scorer_ : function or a dict</span>
<span class="sd">        Scorer function used on the held out data to choose the best</span>
<span class="sd">        parameters for the model.</span>

<span class="sd">        For multi-metric evaluation, this attribute holds the validated</span>
<span class="sd">        ``scoring`` dict which maps the scorer key to the scorer callable.</span>

<span class="sd">    n_splits_ : int</span>
<span class="sd">        The number of cross-validation splits (folds/iterations).</span>

<span class="sd">    refit_time_ : float</span>
<span class="sd">        Seconds used for refitting the best model on the whole dataset.</span>

<span class="sd">        This is present only if ``refit`` is not False.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    multimetric_ : bool</span>
<span class="sd">        Whether or not the scorers compute several metrics.</span>

<span class="sd">    classes_ : ndarray of shape (n_classes,)</span>
<span class="sd">        The classes labels. This is present only if ``refit`` is specified and</span>
<span class="sd">        the underlying estimator is a classifier.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features seen during :term:`fit`. Only defined if</span>
<span class="sd">        `best_estimator_` is defined (see the documentation for the `refit`</span>
<span class="sd">        parameter for more details) and that `best_estimator_` exposes</span>
<span class="sd">        `n_features_in_` when fit.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
<span class="sd">        Names of features seen during :term:`fit`. Only defined if</span>
<span class="sd">        `best_estimator_` is defined (see the documentation for the `refit`</span>
<span class="sd">        parameter for more details) and that `best_estimator_` exposes</span>
<span class="sd">        `feature_names_in_` when fit.</span>

<span class="sd">        .. versionadded:: 1.0</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    GridSearchCV : Does exhaustive search over a grid of parameters.</span>
<span class="sd">    ParameterSampler : A generator over parameter settings, constructed from</span>
<span class="sd">        param_distributions.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The parameters selected are those that maximize the score of the held-out</span>
<span class="sd">    data, according to the scoring parameter.</span>

<span class="sd">    If `n_jobs` was set to a value higher than one, the data is copied for each</span>
<span class="sd">    parameter setting(and not `n_jobs` times). This is done for efficiency</span>
<span class="sd">    reasons if individual jobs take very little time, but may raise errors if</span>
<span class="sd">    the dataset is large and not enough memory is available.  A workaround in</span>
<span class="sd">    this case is to set `pre_dispatch`. Then, the memory is copied only</span>
<span class="sd">    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *</span>
<span class="sd">    n_jobs`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import RandomizedSearchCV</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import uniform</span>
<span class="sd">    &gt;&gt;&gt; iris = load_iris()</span>
<span class="sd">    &gt;&gt;&gt; logistic = LogisticRegression(solver=&#39;saga&#39;, tol=1e-2, max_iter=200,</span>
<span class="sd">    ...                               random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; distributions = dict(C=uniform(loc=0, scale=4),</span>
<span class="sd">    ...                      penalty=[&#39;l2&#39;, &#39;l1&#39;])</span>
<span class="sd">    &gt;&gt;&gt; clf = RandomizedSearchCV(logistic, distributions, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; search = clf.fit(iris.data, iris.target)</span>
<span class="sd">    &gt;&gt;&gt; search.best_params_</span>
<span class="sd">    {&#39;C&#39;: 2..., &#39;penalty&#39;: &#39;l1&#39;}</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_required_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">,</span> <span class="s2">&quot;param_distributions&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">,</span>
        <span class="n">param_distributions</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;2*n_jobs&quot;</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
        <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span> <span class="o">=</span> <span class="n">param_distributions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">refit</span><span class="o">=</span><span class="n">refit</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span>
            <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_run_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluate_candidates</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Search n_iter candidates from param_distributions&quot;&quot;&quot;</span>
        <span class="n">evaluate_candidates</span><span class="p">(</span>
            <span class="n">ParameterSampler</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span>
            <span class="p">)</span>
        <span class="p">)</span>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, S3PRL Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/scripts/furo.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    </body>
</html>